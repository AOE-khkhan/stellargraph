{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stellargraph example 3: partially directed GraphSAGE on a directed CORA citation network\n",
    "\n",
    "This example shows the application of *directed* GraphSAGE to a *directed* graph. However, in order to compare results against example 2, in this example we do not sample from the in-node neighbourhoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import NetworkX and stellar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import DirectedGraphSAGENodeGenerator\n",
    "from stellargraph.layer import DirectedGraphSAGE\n",
    "\n",
    "from keras import layers, optimizers, losses, metrics, Model\n",
    "from sklearn import preprocessing, feature_extraction, model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the CORA network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading the CORA dataset:**\n",
    "    \n",
    "The dataset used in this demo can be downloaded from [here](https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz).\n",
    "\n",
    "The following is the description of the dataset:\n",
    "> The Cora dataset consists of 2708 scientific publications classified into one of seven classes.\n",
    "> The citation network consists of 5429 links. Each publication in the dataset is described by a\n",
    "> 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary.\n",
    "> The dictionary consists of 1433 unique words. The README file in the dataset provides more details.\n",
    "\n",
    "Download and unzip the cora.tgz file to a location on your computer and set the `data_dir` variable to\n",
    "point to the location of the dataset (the directory containing \"cora.cites\" and \"cora.content\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser(\"~/data/cora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the graph from edgelist (in `cited-paper` <- `citing-paper` order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = pd.read_csv(os.path.join(data_dir, \"cora.cites\"), sep='\\t', header=None, names=[\"target\", \"source\"])\n",
    "edgelist[\"label\"] = \"cites\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the graph with directed edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gnx = nx.from_pandas_edgelist(edgelist, edge_attr=\"label\", create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(Gnx, \"paper\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the features and subject for the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"w_{}\".format(ii) for ii in range(1433)]\n",
    "column_names =  feature_names + [\"subject\"]\n",
    "node_data = pd.read_csv(os.path.join(data_dir, \"cora.content\"), sep='\\t', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to train a graph-ML model that will predict the \"subject\" attribute on the nodes. These subjects are one of 7 categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case_Based',\n",
       " 'Genetic_Algorithms',\n",
       " 'Neural_Networks',\n",
       " 'Probabilistic_Methods',\n",
       " 'Reinforcement_Learning',\n",
       " 'Rule_Learning',\n",
       " 'Theory'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(node_data[\"subject\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For machine learning we want to take a subset of the nodes for training, and use the rest for testing. We'll use scikit-learn again to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = model_selection.train_test_split(\n",
    "    node_data, train_size=0.1, test_size=None, stratify=node_data['subject']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note using stratified sampling gives the following counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Probabilistic_Methods': 42,\n",
       "         'Theory': 35,\n",
       "         'Rule_Learning': 18,\n",
       "         'Neural_Networks': 81,\n",
       "         'Genetic_Algorithms': 42,\n",
       "         'Case_Based': 30,\n",
       "         'Reinforcement_Learning': 22})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_data['subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set has class imbalance that might need to be compensated, e.g., via using a weighted cross-entropy loss in model training, with class weights inversely proportional to class support. However, we will ignore the class imbalance in this example, for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to numeric arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our categorical target, we will use one-hot vectors that will be fed into a soft-max Keras layer during training. To do this conversion ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoding = feature_extraction.DictVectorizer(sparse=False)\n",
    "\n",
    "train_targets = target_encoding.fit_transform(train_data[[\"subject\"]].to_dict('records'))\n",
    "test_targets = target_encoding.transform(test_data[[\"subject\"]].to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do the same for the node attributes we want to use to predict the subject. These are the feature vectors that the Keras model will use as input. The CORA dataset contains attributes 'w_x' that correspond to words found in that publication. If a word occurs more than once in a publication the relevant attribute will be set to one, otherwise it will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = node_data[feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the GraphSAGE model in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a StellarGraph object from the NetworkX graph and the node features and targets. It is StellarGraph objects that we use in this library to perform machine learning tasks on.\n",
    "\n",
    "Note that the NetworkX graph is *directed*, so we also treat it here as *directed*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = sg.StellarDiGraph(Gnx, node_features=node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarDiGraph: Directed multigraph\n",
      " Nodes: 2708, Edges: 5429\n",
      "\n",
      " Node types:\n",
      "  paper: [2708]\n",
      "    Edge types: paper-cites->paper\n",
      "\n",
      " Edge types:\n",
      "    paper-cites->paper: [5429]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(G.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed data from the graph to the Keras model we need a data generator that feeds data from the graph to the model. The generators are specialized to the model and the learning task so we choose the `DirectedGraphSAGENodeGenerator` as we are predicting node attributes with a `DirectedGraphSAGE` model.\n",
    "\n",
    "We need two other parameters, the `batch_size` to use for training and the number of nodes to sample at each level of the model, for both the in-node and out-node neighbourhoods. In order to contrast the results with example 2, here we choose a two-level model with 10 out-nodes sampled in the first layer, and 4 out-nodes in the second - we switch off sampling from the in-node neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50; in_samples = [0, 0]; out_samples = [10, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DirectedGraphSAGENodeGenerator` object is required to send the node features in sampled subgraphs to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DirectedGraphSAGENodeGenerator(G, batch_size, in_samples, out_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `generator.flow()` method, we can create iterators over nodes that should be used to train, validate, or evaluate the model. For training we use only the training nodes returned from our splitter and the target values. The `shuffle=True` argument is given to the `flow` method to improve training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator.flow(train_data.index, train_targets, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can specify our machine learning model, we need a few more parameters for this:\n",
    "\n",
    " * the `layer_sizes` is a list of hidden feature sizes of each layer in the model. In this example we use 48-dimensional hidden node features at each layer, which corresponds to 16 weights for a node, 16 for the in-nodes (unused) and 16 for the out-nodes. This corresponds to the 32 dimensions used in example 1 (where we do not distinguish between in-nodes and out-nodes).\n",
    " * The `bias` and `dropout` are internal parameters of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 10:08:37.639082 4535567808 deprecation_wrapper.py:119] From /anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graphsage_model = DirectedGraphSAGE(\n",
    "    layer_sizes=[48, 48],\n",
    "    generator=train_gen,\n",
    "    bias=False,\n",
    "    dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a model to predict the 7 categories using Keras softmax layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 10:08:37.654679 4535567808 deprecation_wrapper.py:119] From /anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0823 10:08:37.660939 4535567808 deprecation_wrapper.py:119] From /anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0823 10:08:37.668406 4535567808 deprecation.py:506] From /anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0823 10:08:37.716286 4535567808 deprecation_wrapper.py:119] From /anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_inp, x_out = graphsage_model.build()\n",
    "prediction = layers.Dense(units=train_targets.shape[1], activation=\"softmax\")(x_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the actual Keras model with the graph inputs `x_inp` provided by the `graph_model` and outputs being the predictions from the softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 10:08:37.997756 4535567808 deprecation_wrapper.py:119] From /anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0823 10:08:38.003920 4535567808 deprecation_wrapper.py:119] From /anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.005),\n",
    "    loss=losses.categorical_crossentropy,\n",
    "    metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, keeping track of its loss and accuracy on the training set, and its generalisation performance on the test set (we need to create another generator over the test data for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = generator.flow(test_data.index, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 10:08:38.170191 4535567808 deprecation.py:323] From /anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 3s - loss: nan - acc: 0.1230 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 2/20\n",
      " - 3s - loss: nan - acc: 0.1059 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 3/20\n",
      " - 2s - loss: nan - acc: 0.1059 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 4/20\n",
      " - 2s - loss: nan - acc: 0.1102 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 5/20\n",
      " - 2s - loss: nan - acc: 0.1144 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 6/20\n",
      " - 2s - loss: nan - acc: 0.1187 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 7/20\n",
      " - 2s - loss: nan - acc: 0.1187 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 8/20\n",
      " - 2s - loss: nan - acc: 0.1144 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 9/20\n",
      " - 2s - loss: nan - acc: 0.1059 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 10/20\n",
      " - 2s - loss: nan - acc: 0.1102 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 11/20\n",
      " - 2s - loss: nan - acc: 0.1187 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 12/20\n",
      " - 2s - loss: nan - acc: 0.1102 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 13/20\n",
      " - 2s - loss: nan - acc: 0.1102 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 14/20\n",
      " - 3s - loss: nan - acc: 0.1102 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 15/20\n",
      " - 2s - loss: nan - acc: 0.1230 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 16/20\n",
      " - 3s - loss: nan - acc: 0.1144 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 17/20\n",
      " - 2s - loss: nan - acc: 0.1059 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 18/20\n",
      " - 2s - loss: nan - acc: 0.1102 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 19/20\n",
      " - 2s - loss: nan - acc: 0.1059 - val_loss: nan - val_acc: 0.1099\n",
      "Epoch 20/20\n",
      " - 2s - loss: nan - acc: 0.1102 - val_loss: nan - val_acc: 0.1099\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    epochs=20,\n",
    "    validation_data=test_gen,\n",
    "    verbose=2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_history(history):\n",
    "    metrics = sorted(history.history.keys())\n",
    "    metrics = metrics[:len(metrics)//2]\n",
    "    for m in metrics:\n",
    "        # summarize history for metric m\n",
    "        plt.plot(history.history[m])\n",
    "        plt.plot(history.history['val_' + m])\n",
    "        plt.title(m)\n",
    "        plt.ylabel(m)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAbK0lEQVR4nO3de7SddX3n8fdHCEQuJZBEKwRNKtQhiEU4YWGpFE2VQG2AGaCoUGgZsaul0y6qQ1zemTWzoKyCtYNcCl2lVcttimYQuUgDYhe3A0UkXCQwEQ4qxkgQL4iB7/yxn9DNYSec5Dx775C8X2udlf38fs/l+zzZ+3zOc9nPk6pCkqQ2vGrYBUiSNh2GiiSpNYaKJKk1hookqTWGiiSpNYaKJKk1hookqTWGiiSpNYaKJKk1hoo0BEkWJXk4ydNJ7ktyRFffB5Lc39W3T9O+a5J/SbIiycok/3t4ayD1tuWwC5A2Uw8Dbwe+DxwFfD7JbsBvAZ8CDgdGgTcCv0yyBXAV8K/AccBzwMjgy5bWLd77Sxq+JHcDnwT+BLi6qv5mXP/bgMXA66pq9RBKlCbEw1/SECT5gyR3J1mVZBXwZmAGsCudvZjxdgW+Y6BoY+fhL2nAkrwB+DtgPnBLVT3X7KkEeIzOIa/xHgNen2RLg0UbM/dUpMHbFihgBUCSP6SzpwJwIfChJPumY7cmhG4HvgecnmTbJFOTHDCM4qV1MVSkAauq+4C/Bm4BngD2Av6t6bsc+J/AF4GngS8BO1XVc8DvAbsBjwJjwO8PvHjpZXiiXpLUGvdUJEmtMVQkSa0xVCRJrTFUJEmt2ay/pzJjxoyaPXv2sMuQpFeUO++884dVNbNX32YdKrNnz2Z0dHTYZUjSK0qS76ytz8NfkqTWGCqSpNYYKpKk1hgqkqTWGCqSpNYYKpKk1hgqkqTWbNbfU9lQdyz/ETd/e8Wwy5CGKxnesr27+qTN3+O1/Mau01qfr6GyAe76zpP87ZJlwy7jFa1quL+TNDkbw+903z+T85pfmWqobCw++Ntv5IO/3euJr5K0efOciiSpNYaKJKk1hookqTWGiiSpNYaKJKk1hookqTWGiiSpNYaKJKk1hookqTWGiiSpNYaKJKk1hookqTWGiiSpNYaKJKk1fQ2VJAuSPJhkWZJFPfoPTHJXktVJjhzXd02SVUmuGtd+cjO/SjKjqz1JPtv03ZNkn/6tmSSpl76FSpItgHOAQ4C5wHuTzB032qPACcAXe8ziTOC4Hu3/BvwO8J1x7YcAuzc/JwHnbmjtkqQN0889lf2AZVX1SFU9C1wCHNY9QlUtr6p7gOfHT1xVNwBP92j/96pa3mN5hwH/WB23AtOSvK6F9ZAkTVA/Q2UX4LGu4bGmbajLS3JSktEkoytW+Jx5SWrTZneivqouqKqRqhqZOXPmsMuRpE1KP0PlcWDXruFZTdumsjxJ0jj9DJU7gN2TzEmyFXAMsLiPy1sM/EFzFdj+wFNV9b0+Lk+SNE7fQqWqVgMnA9cC9wOXVdXSJKclWQiQZF6SMeAo4PwkS9dMn+Rm4HJgfpKxJAc37f+tmWYWcE+SC5tJrgYeAZYBfwf8Sb/WTZLUW6pq2DUMzcjISI2Ojg67DEl6RUlyZ1WN9Orb7E7US5L6x1CRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktaavoZJkQZIHkyxLsqhH/4FJ7kqyOsmR4/quSbIqyVXj2uckua2Z56VJtmraX59kSZJ/T3JPkkP7uW6SpJfqW6gk2QI4BzgEmAu8N8nccaM9CpwAfLHHLM4EjuvRfgZwdlXtBjwJnNi0fwy4rKreChwDfG6y6yBJWj/93FPZD1hWVY9U1bPAJcBh3SNU1fKqugd4fvzEVXUD8HR3W5IA7wSuaJouBg5fMwnwK83rHYDvtrQekqQJ6meo7AI81jU81rRNxnRgVVWt7jHPTwHHJhkDrgb+rNcMkpyUZDTJ6IoVKyZZjiSp26Z0ov69wD9U1SzgUOCfkrxk/arqgqoaqaqRmTNnDrxISdqU9TNUHgd27Rqe1bRNxkpgWpIte8zzROAygKq6BZgKzJjk8iRJ66GfoXIHsHtztdZWdE6eL57MDKuqgCXAmivFjge+3Lx+FJgPkGQPOqHi8S1JGqC+hUpz3uNk4FrgfjpXZi1NclqShQBJ5jXnQI4Czk+ydM30SW4GLgfmJxlLcnDTdSpwSpJldM6xXNS0/yXwgSTfBP4ZOKEJIUnSgGRz/r07MjJSo6Ojwy5Dkl5RktxZVSO9+jalE/WSpCEzVCRJrTFUJEmtMVQkSa0xVCRJrTFUJEmtMVQkSa0xVCRJrTFUJEmtMVQkSa0xVCRJrTFUJEmtMVQkSa0xVCRJrTFUJEmtMVQkSa0xVCRJrTFUJEmtMVQkSa0xVCRJrTFUJEmtMVQkSa0xVCRJrTFUJEmt6WuoJFmQ5MEky5Is6tF/YJK7kqxOcuS4vmuSrEpy1bj2OUlua+Z5aZKtuvqOTnJfkqVJvti/NZMk9bJlv2acZAvgHOBdwBhwR5LFVXVf12iPAicAH+oxizOBbYAPjms/Azi7qi5Jch5wInBukt2BjwAHVNWTSV7T6gpJUuOXv/wlY2NjPPPMM8Mupa+mTp3KrFmzmDJlyoSn6VuoAPsBy6rqEYAklwCHAS+ESlUtb/qeHz9xVd2Q5KDutiQB3gm8r2m6GPgUcC7wAeCcqnqymf4Hra6NJDXGxsbYfvvtmT17Np1fS5ueqmLlypWMjY0xZ86cCU/Xz8NfuwCPdQ2PNW2TMR1YVVWre8zz14FfT/JvSW5NsmCSy5Kknp555hmmT5++yQYKQBKmT5++3ntj/dxTGbQtgd2Bg4BZwNeT7FVVq7pHSnIScBLA61//+kHXKGkTsSkHyhobso793FN5HNi1a3hW0zYZK4FpSdaEYfc8x4DFVfXLqvp/wLfphMyLVNUFVTVSVSMzZ86cZDmSNHirVq3ic5/73HpPd+ihh7Jq1aqXH3ES+hkqdwC7N1drbQUcAyyezAyrqoAlwJorxY4Hvty8/hKdvRSSzKBzOOyRySxPkjZGawuV1atX9xj7P1x99dVMmzatX2UBfQyV5rzHycC1wP3AZVW1NMlpSRYCJJmXZAw4Cjg/ydI10ye5GbgcmJ9kLMnBTdepwClJltE5x3JR034tsDLJfXSC58NVtbJf6ydJw7Jo0SIefvhh9t57b+bNm8fb3/52Fi5cyNy5cwE4/PDD2Xfffdlzzz254IILXphu9uzZ/PCHP2T58uXssccefOADH2DPPffk3e9+Nz//+c9bqS2dP/43TyMjIzU6OjrsMiS9wtx///3sscceAHz6/y7lvu/+uNX5z935V/jk7+251v7ly5fznve8h3vvvZcbb7yR3/3d3+Xee+994SqtH/3oR+y00078/Oc/Z968edx0001Mnz6d2bNnMzo6yk9+8hN22203RkdH2XvvvTn66KNZuHAhxx577DrXdY0kd1bVSK/aNqUT9ZK0Wdpvv/1edNnvZz/7Wa688koAHnvsMR566CGmT5/+omnmzJnD3nvvDcC+++7L8uXLW6nFUJGkSVjXHsWgbLvtti+8vvHGG/na177GLbfcwjbbbMNBBx3U87Lgrbfe+oXXW2yxRWuHvyZ0TiXJEUl26BqeluTwViqQJK2X7bffnqeffrpn31NPPcWOO+7INttswwMPPMCtt9460Nomuqfyyaq6cs1AVa1K8kk6V1xJkgZo+vTpHHDAAbz5zW/m1a9+Na997Wtf6FuwYAHnnXcee+yxB29605vYf//9B1rbhE7UJ7mnqt4yru1bVbVX3yobAE/US9oQvU5eb6rW90T9RC8pHk1yVpI3Nj9nAXdOslZJ0iZmoqHyZ8CzwKXAJcAzwJ/2qyhJ0ivThM6pVNVPgZc8D0WSpG4Tvfrr+iTTuoZ3THJt/8qSJL0STfTw14zuu/02zyzxIViSpBeZaKg8n+SF+8QnmQ1svvd3kST1NNFQ+SjwjST/lOTzwE10Ht0rSRqwDb31PcBnPvMZfvazn7Vc0X+YUKhU1TXACPAg8M/AXwLtfKdfkrReNuZQmdDVX0n+K/DndB6KdTewP3ALnefFS5IGqPvW9+9617t4zWtew2WXXcYvfvELjjjiCD796U/z05/+lKOPPpqxsTGee+45Pv7xj/PEE0/w3e9+l3e84x3MmDGDJUuWtF7bRG/T8ufAPODWqnpHkv8E/K/Wq5GkV5qvLoLvf6vdef7qXnDI6WvtPv3007n33nu5++67ue6667jiiiu4/fbbqSoWLlzI17/+dVasWMHOO+/MV77yFaBzT7AddtiBs846iyVLljBjxox2a25M9JzKM1X1DECSravqAeBNfalIkjRh1113Hddddx1vfetb2WeffXjggQd46KGH2Guvvbj++us59dRTufnmm9lhhx1efmYtmOieyljzPZUvAdcneRL4Tv/KkqRXiHXsUQxCVfGRj3yED37wgy/pu+uuu7j66qv52Mc+xvz58/nEJz7R93om+o36I5qXn0qyBNgBuKZvVUmS1qr71vcHH3wwH//4x3n/+9/Pdtttx+OPP86UKVNYvXo1O+20E8ceeyzTpk3jwgsvfNG0/Tr8td4P6aqqm/pRiCRpYrpvfX/IIYfwvve9j7e97W0AbLfddnz+859n2bJlfPjDH+ZVr3oVU6ZM4dxzzwXgpJNOYsGCBey88859OVHvM+q99b2k9eSt7yd/63tJkl6WoSJJao2hIklqjaEiSRtgczgfvSHraKhI0nqaOnUqK1eu3KSDpapYuXIlU6dOXa/p1vuS4vWRZAHwN8AWwIVVdfq4/gOBzwBvAY6pqiu6+q6hc4+xb1TVe7ra59B5pPF04E7guKp6tqv/vwBXAPOqyku7JLVu1qxZjI2NsWLFimGX0ldTp05l1qxZ6zVN30IlyRbAOcC7gDHgjiSLq+q+rtEeBU4APtRjFmcC2wDjvyZ6BnB2VV2S5DzgRODcZpnb07lP2W0trookvciUKVOYM2fOsMvYKPXz8Nd+wLKqeqTZk7gEOKx7hKpaXlX3AM+Pn7iqbgCe7m5LEjp3Rl6zR3MxcHjXKP+DTug809ZKSJImrp+hsgvwWNfwWNM2GdOBVVW1evw8k+wD7FpVX1nXDJKclGQ0yeimvusqSYO2SZyoT/Iq4Cw6Dw9bp6q6oKpGqmpk5syZ/S9OkjYj/QyVx4Fdu4ZnNW2TsRKYlmTNuaA189weeDNwY5LldE7wL07S8zYCkqT+6Geo3AHsnmROkq2AY4DFk5lhda7fWwIc2TQdD3y5qp6qqhlVNbuqZgO3Agu9+kuSBqtvodKc9zgZuBa4H7isqpYmOS3JQoAk85KMAUcB5ydZumb6JDcDlwPzk4wlObjpOhU4JckyOudYLurXOkiS1o93KfYuxZK0XrxLsSRpIAwVSVJrDBVJUmsMFUlSawwVSVJrDBVJUmsMFUlSawwVSVJrDBVJUmsMFUlSawwVSVJrDBVJUmsMFUlSawwVSVJrDBVJUmsMFUlSawwVSVJrDBVJUmsMFUlSawwVSVJrDBVJUmsMFUlSawwVSVJrDBVJUmv6GipJFiR5MMmyJIt69B+Y5K4kq5McOa7vmiSrklw1rn1OktuaeV6aZKum/ZQk9yW5J8kNSd7Qz3WTJL1U30IlyRbAOcAhwFzgvUnmjhvtUeAE4Is9ZnEmcFyP9jOAs6tqN+BJ4MSm/d+Bkap6C3AF8FeTXQdJ0vrp557KfsCyqnqkqp4FLgEO6x6hqpZX1T3A8+MnrqobgKe725IEeCed0AC4GDi8GX9JVf2sab8VmNXiukiSJqCfobIL8FjX8FjTNhnTgVVVtfpl5nki8NVeM0hyUpLRJKMrVqyYZDmSpG6b3In6JMcCI3QOn71EVV1QVSNVNTJz5szBFidJm7gt+zjvx4Fdu4ZnNW2TsRKYlmTLZm/lRfNM8jvAR4HfrqpfTHJZkqT11M89lTuA3ZurtbYCjgEWT2aGVVXAEmDNlWLHA18GSPJW4HxgYVX9YDLLkSRtmL6FSrMncTJwLXA/cFlVLU1yWpKFAEnmJRkDjgLOT7J0zfRJbgYuB+YnGUtycNN1KnBKkmV0zrFc1LSfCWwHXJ7k7iSTCjBJ0vpL54//zdPIyEiNjo4OuwxJekVJcmdVjfTq2+RO1EuShsdQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLXGUJEktcZQkSS1xlCRJLWmr6GSZEGSB5MsS7KoR/+BSe5KsjrJkeP6rkmyKslV49rnJLmtmeelSbZq2rduhpc1/bP7uW6SpJfqW6gk2QI4BzgEmAu8N8nccaM9CpwAfLHHLM4EjuvRfgZwdlXtBjwJnNi0nwg82bSf3YwnSRqgfu6p7Acsq6pHqupZ4BLgsO4Rqmp5Vd0DPD9+4qq6AXi6uy1JgHcCVzRNFwOHN68Pa4Zp+uc340uSBqSfobIL8FjX8FjTNhnTgVVVtbrHPF9YXtP/VDO+JGlANrsT9UlOSjKaZHTFihXDLkeSNin9DJXHgV27hmc1bZOxEpiWZMse83xheU3/Ds34L1JVF1TVSFWNzJw5c5LlSJK69TNU7gB2b67W2go4Blg8mRlWVQFLgDVXih0PfLl5vbgZpun/12Z8SdKA9C1UmvMaJwPXAvcDl1XV0iSnJVkIkGRekjHgKOD8JEvXTJ/kZuByOifcx5Ic3HSdCpySZBmdcyYXNe0XAdOb9lOAl1zCLEnqr2zOf8yPjIzU6OjosMuQpFeUJHdW1Uivvs3uRL0kqX8MFUlSawwVSVJrDBVJUmsMFUlSawwVSVJrtnz5UfQSX10E3//WsKuQpA33q3vBIae3Plv3VCRJrXFPZUP0Id0laVPgnookqTWGiiSpNYaKJKk1hookqTWGiiSpNYaKJKk1hookqTWGiiSpNZv1kx+TrAC+s4GTzwB+2GI5bbO+ybG+ydvYa7S+DfeGqprZq2OzDpXJSDK6tsdpbgysb3Ksb/I29hqtrz88/CVJao2hIklqjaGy4S4YdgEvw/omx/omb2Ov0fr6wHMqkqTWuKciSWqNoSJJao2h8jKSLEjyYJJlSRb16N86yaVN/21JZg+wtl2TLElyX5KlSf68xzgHJXkqyd3NzycGVV+z/OVJvtUse7RHf5J8ttl+9yTZZ4C1valru9yd5MdJ/mLcOAPffkn+PskPktzb1bZTkuuTPNT8u+Napj2+GeehJMcPqLYzkzzQ/P9dmWTaWqZd53uhzzV+KsnjXf+Ph65l2nV+3vtY36VdtS1Pcvdaph3INpyUqvJnLT/AFsDDwK8BWwHfBOaOG+dPgPOa18cAlw6wvtcB+zSvtwe+3aO+g4CrhrgNlwMz1tF/KPBVIMD+wG1D/L/+Pp0vdQ11+wEHAvsA93a1/RWwqHm9CDijx3Q7AY80/+7YvN5xALW9G9iyeX1Gr9om8l7oc42fAj40gffAOj/v/apvXP9fA58Y5jaczI97Kuu2H7Csqh6pqmeBS4DDxo1zGHBx8/oKYH6SDKK4qvpeVd3VvH4auB/YZRDLbtFhwD9Wx63AtCSvG0Id84GHq2pD77DQmqr6OvCjcc3d77OLgcN7THowcH1V/aiqngSuBxb0u7aquq6qVjeDtwKz2lzm+lrL9puIiXzeJ21d9TW/O44G/rnt5Q6KobJuuwCPdQ2P8dJf2i+M03ywngKmD6S6Ls1ht7cCt/XofluSbyb5apI9B1oYFHBdkjuTnNSjfyLbeBCOYe0f5GFuvzVeW1Xfa15/H3htj3E2hm35R3T2PHt5ufdCv53cHKL7+7UcPtwYtt/bgSeq6qG19A97G74sQ2UTkGQ74P8Af1FVPx7XfRedQzq/Afwt8KUBl/dbVbUPcAjwp0kOHPDyX1aSrYCFwOU9uoe9/V6iOsdBNrrvAiT5KLAa+MJaRhnme+Fc4I3A3sD36Bxi2hi9l3XvpWz0nydDZd0eB3btGp7VtPUcJ8mWwA7AyoFU11nmFDqB8oWq+pfx/VX146r6SfP6amBKkhmDqq+qHm/+/QFwJZ1DDN0mso377RDgrqp6YnzHsLdflyfWHBZs/v1Bj3GGti2TnAC8B3h/E3ovMYH3Qt9U1RNV9VxVPQ/83VqWPdT3YvP74z8Dl65tnGFuw4kyVNbtDmD3JHOav2aPARaPG2cxsOYqmyOBf13bh6ptzfHXi4D7q+qstYzzq2vO8STZj87/+UBCL8m2SbZf85rOCd17x422GPiD5iqw/YGnug7zDMpa/zoc5vYbp/t9djzw5R7jXAu8O8mOzeGddzdtfZVkAfDfgYVV9bO1jDOR90I/a+w+T3fEWpY9kc97P/0O8EBVjfXqHPY2nLBhXymwsf/QuTrp23SuCvlo03YanQ8QwFQ6h02WAbcDvzbA2n6LzmGQe4C7m59DgT8G/rgZ52RgKZ0rWW4FfnOA9f1as9xvNjWs2X7d9QU4p9m+3wJGBvz/uy2dkNihq22o249OwH0P+CWd4/on0jlPdwPwEPA1YKdm3BHgwq5p/6h5Ly4D/nBAtS2jcy5izXtwzdWQOwNXr+u9MMDt90/N++seOkHxuvE1NsMv+bwPor6m/R/WvO+6xh3KNpzMj7dpkSS1xsNfkqTWGCqSpNYYKpKk1hgqkqTWGCqSpNYYKtIrVHMH5auGXYfUzVCRJLXGUJH6LMmxSW5vnoFxfpItkvwkydnpPAfnhiQzm3H3TnJr17NJdmzad0vytebGlncleWMz++2SXNE8z+QLg7pDtrQ2horUR0n2AH4fOKCq9gaeA95P55v8o1W1J3AT8Mlmkn8ETq2qt9D5Bvia9i8A51Tnxpa/Secb2dC5M/VfAHPpfOP6gL6vlLQOWw67AGkTNx/YF7ij2Yl4NZ2bQT7Pf9w48PPAvyTZAZhWVTc17RcDlzf3e9qlqq4EqKpnAJr53V7NvaKapwXOBr7R/9WSejNUpP4KcHFVfeRFjcnHx423ofdL+kXX6+fwM60h8/CX1F83AEcmeQ288Kz5N9D57B3ZjPM+4BtV9RTwZJK3N+3HATdV56meY0kOb+axdZJtBroW0gT5V43UR1V1X5KP0Xla36vo3Jn2T4GfAvs1fT+gc94FOre1P68JjUeAP2zajwPOT3JaM4+jBrga0oR5l2JpCJL8pKq2G3YdUts8/CVJao17KpKk1rinIklqjaEiSWqNoSJJao2hIklqjaEiSWrN/wfP6ndp9R/GdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have trained the model we can evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics:\n",
      "\tloss: nan\n",
      "\tacc: 0.1099\n"
     ]
    }
   ],
   "source": [
    "test_metrics = model.evaluate_generator(test_gen)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the predictions themselves for all nodes using another node iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = node_data.index\n",
    "all_mapper = generator.flow(all_nodes)\n",
    "all_predictions = model.predict_generator(all_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions will be the output of the softmax layer, so to get final categories we'll use the `inverse_transform` method of our target attribute specifcation to turn these values back to the original categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-393fbf5374a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnode_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_encoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/sklearn/feature_extraction/dict_vectorizer.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X, dict_type)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# COO matrix is not subscriptable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/stellargraph-py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "node_predictions = target_encoding.inverse_transform(all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(node_predictions, index=all_nodes).idxmax(axis=1)\n",
    "df = pd.DataFrame({\"Predicted\": results, \"True\": node_data['subject']})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the predictions to the graph, and save as graphml, e.g. for visualisation in [Gephi](https://gephi.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nid, pred, true in zip(df.index, df[\"Predicted\"], df[\"True\"]):\n",
    "    Gnx.node[nid][\"subject\"] = true\n",
    "    Gnx.node[nid][\"PREDICTED_subject\"] = pred.split(\"=\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also add isTrain and isCorrect node attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nid in train_data.index:\n",
    "    Gnx.node[nid][\"isTrain\"] = True\n",
    "    \n",
    "for nid in test_data.index:\n",
    "    Gnx.node[nid][\"isTrain\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nid in Gnx.nodes():\n",
    "    Gnx.node[nid][\"isCorrect\"] = Gnx.node[nid][\"subject\"] == Gnx.node[nid][\"PREDICTED_subject\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node embeddings\n",
    "Evaluate node embeddings as activations of the output of graphsage layer stack, and visualise them, coloring nodes by their subject label.\n",
    "\n",
    "The GraphSAGE embeddings are the output of the GraphSAGE layers, namely the `x_out` variable. Let's create a new model with the same inputs as we used previously `x_inp` but now the output is the embeddings rather than the predicted class. Additionally note that the weights trained previously are kept in the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Model(inputs=x_inp, outputs=x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embedding_model.predict_generator(all_mapper)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project the embeddings to 2d using either TSNE or PCA transform, and visualise, coloring nodes by their subject label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = emb\n",
    "y = np.argmax(target_encoding.transform(node_data[[\"subject\"]].to_dict('records')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X.shape[1] > 2:\n",
    "    transform = TSNE #PCA \n",
    "\n",
    "    trans = transform(n_components=2)\n",
    "    emb_transformed = pd.DataFrame(trans.fit_transform(X), index=node_data.index)\n",
    "    emb_transformed['label'] = y\n",
    "else:\n",
    "    emb_transformed = pd.DataFrame(X, index=node_data.index)\n",
    "    emb_transformed = emb_transformed.rename(columns = {'0':0, '1':1})\n",
    "    emb_transformed['label'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.7\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(emb_transformed[0], emb_transformed[1], c=emb_transformed['label'].astype(\"category\"), \n",
    "            cmap=\"jet\", alpha=alpha)\n",
    "ax.set(aspect=\"equal\", xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
    "plt.title('{} visualization of GraphSAGE embeddings for cora dataset'.format(transform.__name__))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
